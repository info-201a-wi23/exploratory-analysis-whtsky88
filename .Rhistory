# `sum()` function for practice.
?sum
# Pick two of your favorite numbers (between 1 and 100) and assign them to
# variables `fav_1` and `fav_2`
fav_1 <- 16
fav_2 <- 7
# Divide each number by the square root of 201 and save the new value in the
# original variable
fav_1 <- (fav_1)/(sqrt(201))
fav_2 <- (fav_2)/(sqrt(201))
# Create a variable `raw_sum` that is the sum of the two variables. Use the
# `sum()` function for practice.
raw_sum <- sum(fav_1, fav_2)
# Create a variable `round_sum` that is the `raw_sum` rounded to 1 decimal place.
# Use the `round()` function.
round_sum <- round(raw_sum, 1)
# Pick two of your favorite numbers (between 1 and 100) and assign them to
# variables `fav_1` and `fav_2`
fav_1 <- 16
fav_2 <- 7
# Divide each number by the square root of 201 and save the new value in the
# original variable
fav_1 <- (fav_1)/(sqrt(201))
fav_2 <- (fav_2)/(sqrt(201))
# Create a variable `raw_sum` that is the sum of the two variables. Use the
# `sum()` function for practice.
raw_sum <- sum(fav_1, fav_2)
# Create a variable `round_sum` that is the `raw_sum` rounded to 1 decimal place.
# Use the `round()` function.
round_sum <- round(raw_sum, 1)
# Create two new variables `round_1` and `round_2` that are your `fav_1` and
# `fav_2` variables rounded to 1 decimal places
round_1 <- round(fav_1, 1)
round_2 <- round(fav_2, 1)
# Create a variable `sum_round` that is the sum of the rounded values
sum_round <- sum(round_1, round_2)
# Which is bigger, `round_sum` or `sum_round`? (You can use the `max()` function!)
paste(max(round_sum, round_sum))
# Create a variable `sum_round` that is the sum of the rounded values
sum_round <- sum(round_1, round_2)
# Which is bigger, `round_sum` or `sum_round`? (You can use the `max()` function!)
max(round_sum, round_sum)
# (1.a) Load the `stringr` package, which you will use later. (1 point)
library(stringr)
# (1.b) Load the data from CountLove by using the following URL: c
# Save this dataframe into a variable called `protest_data` (1 point)
protest_data <- read.csv("https://countlove.org/data/data.csv", stringsAsFactors = FALSE)
#  Whenever we load data, the first thing we want to do is manually examine it, see how it looks, and make sure we understand what each column (or feature) and each row (or record) in the dataset means.
# Open the dataframe by clicking the spreadsheet icon in the Environment or by using View(). Manually examine the data by scrolling through it.
View(protest_data)
# (1.e) How many protests are recorded in the dataset in total? Use an R function to determine this number and then save it in a variable called `num_protests`  (1 point)
num_protests <- nrow(protest_data)
# (1.f) How many features (or columns) are recorded for each protest? It's important to know how to find this number programmatically as well as manually
# Save the number of features for each protest in a variable called `num_features` (1 point)
num_features <- ncol(protest_data)
# (2.a) Extract the `Attendees` column into a variable called `num_attendees`  (1 point)
num_attendees <- protest_data$Attendees
# (2.b) What is the fewest number of attendees at a protest?
# Save the number of protests in a variable called `min_attendees` (2 points)
# Hint: Remember to exclude NA values when using the functions below!
min_attendees <- min(num_attendees, na.rm = TRUE)
# (2.c) What is the greatest number of attendees at a protest?
# Save the number of protests in a variable called `max_attendees` (2 points)
max_attendees <- max(num_attendees, na.rm = TRUE)
# (2.d) What is the average (mean) number of attendees at a protest?
# Save the number of protests in a variable called `mean_attendees` (2 points)
mean_attendees <- mean(num_attendees, na.rm = TRUE)
# (2.e) What is the median number of attendees?
# Save the number of protests in a variable called `median_attendees` (2 points)
median_attendees <- median(num_attendees, na.rm = TRUE)
# (2.f) What is the difference between the mean and median number of attendees? Subtract median_attendees from mean_attendees
# Save the difference in a variable called `difference_attendees` (1 point)
difference_attendees <- mean_attendees - median_attendees
# (3.a) Extract the `Location` column into a variable called `locations` (1 point)
locations <- protest_data$Location
# (3.b) How many *unique* locations are in the dataset?
# Save the number of unique locations in a variable called `num_locations` (1 point)
num_locations <- unique(locations)
# (3.c) How many protests occurred in the state of Washington?
# Use a function from the stringr package to detect the letters "WA" in the Location column and filter to only keep WA locations
# Then, calculate the number of protests recorded in Washington
# Save the number of WA locations in a variable called `num_in_wa` (3 points)
num_in_wa <- sum(str_detect(locations, "WA"))
# (3.d) What proportion of protests occurred in Washington?
# Divide the number of protests in Washington by the total number of protests
# Save this proportion in a variable called `prop_in_wa` (1 point)
prop_in_wa <- num_in_wa/num_protests
# (3.e) Now, using the same stringr function and building on the code that you've written above, write a function `count_protests_in_location()` that accepts a location and then returns (not prints) the following sentence: "There were [N] protests in [LOCATION]."
# For example: "There were 20 protests in Seattle." "There were 50 protests in NY."
# If the location is not found in the dataset, the function should return the sentence: "Sorry, that location is not found." (6 points)
count_protests_in_location <- function(location) {
num_in_location <- sum(str_detect(locations, location))
if(num_in_location > 0) {
statement <-str_glue("There were ", as.character(num_in_location), " protests in ", location, ".")
return(statement)
} else {
return("Sorry, that location is not found.")
}
}
# (3.f) Use your `count_protests_in_location()` function above to compute the number of protests in "Washington, DC" and return the resulting message
# Save the resulting message in a variable called `dc_summary` (1 point)
dc_summary <- count_protests_in_location("Washington, DC")
# (3.g) Use your function above to compute the number of protests in "Minneapolis" and return the resulting message (1 point)
# # Save the resulting message in a variable called `minneapolis_summary`
minneapolis_summary <- count_protests_in_location("Minneapolis")
# (3.h) Let's try to find out how many protests occurred in each state. To do so, first use a stringr function to extract the last 2 characters from every location and use these 2 characters to create a new vector called `states` (3 points)
states <- toupper(str_sub(locations, -2))
# (3.i) How many unique states are in the dataset? Create a vector of just the unique states in the dataset
# Save the unique states in a variable called `uniq_states` (1 point)
uniq_states <- unique(states)
# (3.j) Now apply your `count_protests_in_location` function to every state in`uniq_states` by using the `sapply()` function.
# Store all your messages in a variable called `state_summary`  (4 points)
state_summary <- sapply(uniq_states, count_protests_in_location)
# (4a) Extract the `Date` column and convert it into a data by using the `as.Date()` function.
# Save this value in a variable called `dates` (2 points)
dates <- as.Date(protest_data$Date)
# (4.b) What is the most recent date in the dataset? (2 point)
# Store this value in a variable called `most_recent_protest`
most_recent_protest <- max(dates)
# (4.c) What is the earliest date in the dataset? (2 point)
# Store this value in a variable called `earliest_protest`
earliest_protest <- min(dates)
# (4.d) What is the timespan of the dataset â€” in other words, the distance between the earliest protest and most recent protest? (1 point)
# Hint: R can do math with dates pretty well by default!
# Store this value in a variable called `time_span`
time_span <- most_recent_protest - earliest_protest
View(dates)
# (4.e) Now, create a vector of only the dates that are in 2020.
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[[dates > 2020-01-01]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates > 2020-01-01]
View(dates)
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates > 2020-01-01]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates > '2020-01-01']
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates > "2020-01-01"]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates == "2020.*"]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates == "2020."]
# (4.f) Create a vector of only the dates that are in 2019. (2 points)
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2019`
protests_in_2019 <- dates[dates == "2019."]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates >= "2020-01-01" & dates <= "2021-01-01"]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates >= "2020-01-01" & dates < "2021-01-01"]
# (4.f) Create a vector of only the dates that are in 2019. (2 points)
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2019`
protest_in_2020 <- dates[dates >= "2019-01-01" & dates <= "2020-01-01"]
# (4.e) Now, create a vector of only the dates that are in 2020.
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2020` (2 points)
protest_in_2020 <- dates[dates >= "2020-01-01" & dates < "2021-01-01"]
# (4.f) Create a vector of only the dates that are in 2019. (2 points)
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2019`
protest_in_2019 <- dates[dates >= "2019-01-01" & dates < "2020-01-01"]
# (4.f) Create a vector of only the dates that are in 2018. (2 points)
# Note: If you want only dates after a certain start date, you can use "2020-01-01" with comparison operators (==, >=, <=)
# Store this value in a variable called `protests_in_2018`
protest_in_2018 <- dates[dates >= "2018-01-01" & dates < "2019-01-01"]
# (4.g) Now use the length() function to find out how many protests happened in 2018 vs. 2019 vs. 2020.
# Save them in the varaibles `num_protets_in_2018`, `num_protets_in_2019`, `num_protets_in_20120`(3 points)
num_protests_in_2018 <- length(protest_in_2018)
num_protests_in_2019 <- length(protest_in_2019)
num_protests_in_2020 <- length(protest_in_2020)
# (5.a) Extract the `Event..legacy..see.tags.` column into a variable called `purposes` (1 point)
purposes <- protest_data$Event..legacy..see.tags.
# (5.b) How many different unique purposes are listed in the dataset? (1 point)
# Save this number in a variable called `num_purposes`
num_purposes <- unique(purposes)
# That's quite a few! Use View() to examine the `purposes` vector. You will notice a common pattern for each purpose, formatted something like this: Civil Rights (Transgender Rights)
View(purposes)
# That's quite a few! Use View() to examine the `purposes` vector. You will notice a common pattern for each purpose, formatted something like this: Civil Rights (Transgender Rights)
View(purposes)
View(purposes)
purposes
# There are some built-in R functions where you can replace text using regular expressions.
# Regular expressions are a special syntax that lets you match patterns.
# For example, see what happens when you run the code below, and use the help() function to learn more about this function
gsub("@.*", "", "melwalsh@uw.edu")
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- purposes[gsub("(.*", "", purposes]
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- purposes[lapply(purposes, gsub("(.*", ""))]
# (5.a) Extract the `Event..legacy..see.tags.` column into a variable called `purposes` (1 point)
purposes <- protest_data$Event..legacy..see.tags.
# (5.b) How many different unique purposes are listed in the dataset? (1 point)
# Save this number in a variable called `num_purposes`
num_purposes <- unique(purposes)
# That's quite a few! Use View() to examine the `purposes` vector. You will notice a common pattern for each purpose, formatted something like this: Civil Rights (Transgender Rights)
View(purposes)
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- purposes[lapply(purposes, gsub("(.*", ""))]
?extract
extract()
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub("(.*", "", purposes)
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub("(.", "", purposes)
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub(" (.*", "", purposes)
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub("\\(.*", "", purposes)
?table()
?table
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub("\\(.+", "", purposes)
# That's quite a few! Use View() to examine the `purposes` vector. You will notice a common pattern for each purpose, formatted something like this: Civil Rights (Transgender Rights)
View(purposes)
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub("\\(.+", "", purposes)
# (5.c) To get a summary of just the higher level categories (e.g., just "Civil Rights" and not "(Transgender Rights)"), we're going to use some R functions to extract only the text before the parenthesis and then save them in a variable `high_level_purposes` (5 points)
high_level_purposes <- gsub("\\(.*", "", purposes)
# There are some built-in R functions where you can replace text using regular expressions.
# Regular expressions are a special syntax that lets you match patterns.
# For example, see what happens when you run the code below, and use the help() function to learn more about this function
gsub("@.*", "", "melwalsh@uw.edu")
# Note: Some regular expression characters, like parenthesis, have a special meaning, so if you want to use them, you need to first "escape" them: https://uc-r.github.io/regex#metacharacters
# See what happens when you run the code below, and use the help() function to learn more about this function
trimws(" hello ")
?table()
# Make a table of your `high_level_protests` by using table() and then View() it
table(high_level_protests)
high_level_protests <- trimws(high_level_purposes)
# Make a table of your `high_level_protests` by using table() and then View() it
table(high_level_protests)
# Make a table of your `high_level_protests` by using table() and then View() it
high_level_protests <- table(high_level_purposes)
# Make a table of your `high_level_protests` by using table() and then View() it
high_level_protests <- table(high_level_purposes)
View(high_level_protests)
high_level_protests <- trimws(high_level_purposes)
View(table(high_level_protests))
styler:::set_style_transformers()
styler:::set_style_transformers()
x <- c(96, 97, 98, 99, 100, 101, 102, 103, 104)
> p <- c(.15, .12, .14, .25, .17, .06, .05, .04, .02)
> X <- sample(x, 1000, replace=T, prob=p) # sample 1000 times from the distribution
> Z <- 800-300*(X-100)*(X > 100) # compute the profit
p <- c(.15, .12, .14, .25, .17, .06, .05, .04, .02)
X <- sample(x, 1000, replace=T, prob=p) # sample 1000 times from the distribution
Z <- 800-300*(X-100)*(X > 100) # compute the profit
Z[1:10]
X[1:10]
Z[1:10]
set.seed(390)
N_TRIALS = 1000
realizations = sample(c(-1,0,1), N_TRIALS, replace = T, prob = c(0.2, 0.4, 0.4))
unique_levels <- sort(unique(realizations))
count <- as.numeric(table(realizations))
plot(unique_levels, count/N_TRIALS, type = "h", xlab = "x", ylim = c(0,0.5),
ylab = "relative frequency/probability", main = "histogram and pmf compared")
points(c(-0.98,0.02,1.02), c(0.2, 0.4, 0.4), col = "red", type = "h")
?plot
X[1:10]
Z[1:10]
unique_levels <- sort(unique(X))
count <- as.numeric(table(X))
plot(unique_levels, count/1000, type = "h", xlab = "x", ylim = c(0,0.5),
ylab = "relative frequency/probability", main = "histogram and pmf compared")
summary(z)
summary(Z)
sd(Z)
e(Z)
1-(sum((X[X>100]))/1000
1-(sum((X[X>100]))/1000
X[X>100]
sum(X[X>100])
length(X[X>100])
1-(length(X[X>100])/1000)
length(X[X<=100])/1000
length(X[98<X<=102])/1000
(length(X[X==99])+length(X[X==100])+length(X[X==101])+length(X[X=102]))/1000
x <- c(96, 97, 98, 99, 100, 101, 102, 103, 104)
p <- c(.15, .12, .14, .25, .17, .06, .05, .04, .02)
X <- sample(x, 1000, replace=T, prob=p) # sample 1000 times from the distribution
Z <- 800-300*(X-100)*(X > 100) # compute the profit
X[1:10]
Z[1:10]
points(x, p, col = "red", type = "h")
points(x + .1, p, col = "red", type = "h")
x <- c(96, 97, 98, 99, 100, 101, 102, 103, 104)
p <- c(.15, .12, .14, .25, .17, .06, .05, .04, .02)
X <- sample(x, 1000, replace=T, prob=p) # sample 1000 times from the distribution
Z <- 800-300*(X-100)*(X > 100) # compute the profit
X[1:10]
Z[1:10]
unique_levels <- sort(unique(X))
count <- as.numeric(table(X))
plot(unique_levels, count/1000, type = "h", xlab = "x", ylim = c(0,0.5),
ylab = "relative frequency/probability", main = "histogram and pmf compared")
points(x + .1, p, col = "red", type = "h")
length(X[X<=100])/1000
(length(X[X==99])+length(X[X==100])+length(X[X==101])+length(X[X=102]))/1000
summary[Z]
summary(Z)
sd(Z)
profit = length(X[X<=100])/1000
(length(Z[Z == 800]) * profit + length(Z[Z == 500]) * length(X[X == 101])/1000
+ length(Z[Z == -400]) * length(X[X==104])/1000
sd(Z)
(length(Z[Z == 800]) * profit + length(Z[Z == 500]) * length(X[X == 101])/1000
+ length(Z[Z == 200]) * length(X[X==102])/1000 + length(Z[Z == -100]) * length(X[X==103])/1000
+ length(Z[Z == -400]) * length(X[X==104])/1000)
sd(Z)
x <- c(96, 97, 98, 99, 100, 101, 102, 103, 104)
p <- c(.15, .12, .14, .25, .17, .06, .05, .04, .02)
X <- sample(x, 1000, replace=T, prob=p) # sample 1000 times from the distribution
Z <- 800-300*(X-100)*(X > 100) # compute the profit
X[1:10]
Z[1:10]
unique_levels <- sort(unique(X))
count <- as.numeric(table(X))
plot(unique_levels, count/1000, type = "h", xlab = "x", ylim = c(0,0.5),
ylab = "relative frequency/probability", main = "histogram and pmf compared")
points(x + .1, p, col = "red", type = "h")
profit = length(X[X<=100])/1000
x <- c(96, 97, 98, 99, 100, 101, 102, 103, 104)
p <- c(.15, .12, .14, .25, .17, .06, .05, .04, .02)
X <- sample(x, 1000, replace=T, prob=p) # sample 1000 times from the distribution
Z <- 800-300*(X-100)*(X > 100) # compute the profit
X[1:10]
Z[1:10]
unique_levels <- sort(unique(X))
count <- as.numeric(table(X))
plot(unique_levels, count/1000, type = "h", xlab = "x", ylim = c(0,0.5),
ylab = "relative frequency/probability", main = "histogram and pmf compared")
points(x + .1, p, col = "red", type = "h")
profit = length(X[X<=100])/1000
(length(X[X==99])+length(X[X==100])+length(X[X==101])+length(X[X=102]))/1000
(length(Z[Z == 800]) * profit + length(Z[Z == 500]) * length(X[X == 101])/1000
+ length(Z[Z == 200]) * length(X[X==102])/1000 + length(Z[Z == -100]) * length(X[X==103])/1000
+ length(Z[Z == -400]) * length(X[X==104])/1000)
sd(Z)
set.seed(390)
N_TRIALS = (1000)
p = 0.0794
realizations = rgeom(N_TRIALS, p)+1
hist(realizations, breaks = 50, freq = FALSE,
main = "Histogram of 1000 Random Realizations of Geo(0.0794)")
x <- seq(0, 80, length.out = 81)
y <- dgeom(x, p)
lines(x, y, col = "red")
mean(realizations)
set.seed(390)
N_TRIALS = (1000)
p = 0.0794
realizations = rgeom(N_TRIALS, p)+1
hist(realizations, breaks = 50, freq = FALSE,
main = "Histogram of 1000 Random Realizations of Geo(0.0794)")
x <- seq(0, 80, length.out = 81)
y <- dgeom(x, p)
lines(x, y, col = "red")
mean(realizations)
sd(realizations)
length(realizations[realizations == 24])/N_TRIALS
1-pnorm(310,301,4)
pnorm(323,301,4)
pnorm(311,301,4)
1-(0.9937903^(20))
# Load libraries
library("dplyr")
library("stringr")
library("ggplot2")
# Exercise 1: Load the data
# Download and unzip one or more of the SPL datasets and load here from a file path
spl_df <- read.csv("~/Desktop/2022-2023-All-Checkouts-SPL-Data.csv", stringsAsFactors = FALSE)
# # load necessary library: dplyr, ggplot2
library(dplyr)
library(ggplot2)
library("scales")
#
# # load states dataframe into variable `covid` and filter for most recent data
covid <- read.csv("https://github.com/melaniewalsh/Neat-Datasets/raw/main/us-states-covid-2023.csv", stringsAsFactors = FALSE) %>%
filter(date == max(date, na.rm=T))
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- covid %>%
select(state, cases, deaths) %>%
arrange(-cases) %>%
slice_head(n=5)
agg_table
layoffs <- read.csv("https://www.kaggle.com/datasets/salimwid/technology-company-layoffs-20222023-data?select=tech_layoffs.csv", stringsAsFactors = FALSE) %>%
filter(date == max(date, na.rm=T))
layoffs <- read.csv("https://www.kaggle.com/datasets/salimwid/technology-company-layoffs-20222023-data?select=tech_layoffs.csv", stringsAsFactors = FALSE)
View(layoffs)
View(layoffs)
layoffs <- read.csv("tech_layoffs.csv", stringsAsFactors = FALSE)
setwd("~/Documents/INFO201/exploratory-analysis-whtsky88")
layoffs <- read.csv("tech_layoffs.csv", stringsAsFactors = FALSE)
View(layoffs)
# # load necessary library: dplyr, ggplot2
library(dplyr)
library(ggplot2)
library("scales")
#
# # load states dataframe into variable `covid` and filter for most recent data
layoffs <- read.csv("tech_layoffs.csv", stringsAsFactors = FALSE)
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>%
select(company, total_layoffs, industry) %>%
arrange(-total_layoffs) %>%
slice_head(n=5)
View(layoffs)
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>%
select(company, total_layoffs, industry) %>%
arrange(+total_layoffs) %>%
slice_head(n=5)
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>%
select(company, total_layoffs, industry) %>%
slice_head(n=5)
agg_table
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>%
select(total_layoffs, company, industry) %>% arrange(-total_layoffs) %>%
slice_head(n=5)
rlang::last_error()
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>% filter(total_layoffs > 0) %>%
select(total_layoffs, company, industry) %>% arrange(-total_layoffs) %>%
slice_head(n=5)
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>% filter(total_layoffs != "Unclear") %>%
select(total_layoffs, company, industry) %>% arrange(-total_layoffs) %>%
slice_head(n=5)
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>% filter(total_layoffs != "Unclear") %>%
select(total_layoffs, company, industry) %>% slice_head(n=5)
agg_table
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>% filter(total_layoffs != "Unclear") %>%
select(company, total_layoffs, industry) %>% slice_head(n=5)
agg_table
# Subset the `covid` dataframe for our table. What we want to show:
# - select the state, cases, and deaths columns
# - sort in descending order by cases
# - slice the top 5 rows
agg_table <- layoffs %>% filter(total_layoffs != "Unclear") %>%
mutate(total_layoffs = as.numeric(total_layoffs)) %>% arrange(-total_layoffs) %>%
select(company, total_layoffs, industry) %>% slice_head(n=5)
agg_table
# # load necessary library: dplyr, ggplot2
library(dplyr)
library(ggplot2)
library("scales")
#
# # load layoff dataframe into variable `layoffs`
layoffs <- read.csv("tech_layoffs.csv", stringsAsFactors = FALSE)
# Subset the `covid` dataframe for our table. What we want to show:
# - select the total_layoffs, company, industry
# - sort in descending order by total_layoffs
# - slice the top 5 rows
agg_table <- layoffs %>% filter(total_layoffs != "Unclear") %>%
mutate(total_layoffs = as.numeric(total_layoffs)) %>% arrange(-total_layoffs) %>%
select(company, total_layoffs, industry) %>% slice_head(n=5)
agg_table
